\chapter{Zrýchlenie FSFSOD}\label{chap:proposal}

Ako sme videli v predošlej kapitole fine-tuning Frustratingly simple few shot object detection trvá pomere dlho a v žiadnom prípade sa nedá použiť v real-time na učenie nových objektov. Preto sa v tejto kapitole pozrieme na to ako by sa dal zrýchliť. 

\section{Zrýchlenie pomocou zmeny parametrov}

Pri pokuse o zrýchlenie fine-tuningu mi ako prvé napadlo zmena trénovacích parametrov. Parametre ktoré majú vplyv na dĺžku tréningu sú batch-size a počet trénovacích iterácii. Pri batch-size sme obmedzený pamäťou našej grafickej karty a maximálny batch size, ktorý zvladne je 2, takže s týmto parametrom nepohneme. Avšak všimol som si, že počas fine-tuningu sa náš model trénuje na začiatku veľmi rýchlo a časom sa veľmi spomaluje. 

Najobjektívnejšiu metriku ktorú máme počas tréningu je total loss. Vyskúšame ako sa mení počas 1-shot fine-tuningu. Na začiatku má hodnotu 0.7237 a na konci 0.09278. Behom prvej minúty klesne približne na 0.25. Po piatich minútach ma hodnotu 0.17. Po 20 minútach je na hodnote 0.13 a ďalších 35minút veľmi pomaly klesá až na finálnu hodnotu 0.09278. Celý priebeh vidíme na obrázku \ref{fig:image5}.

\begin{figure}[H]
\includegraphics[width=\textwidth]{images/1_shot_training_curve.png}
\centering
\caption{Celková strata počas tréningu}
\label{fig:image5}
\end{figure}

Už po piatich minútach máme náš model podľa tejto metriky výrazne natrénovaný. Pozrime sa teda na ostatné metriky presnosti po 5tich minútach tréningu. Vyskúšame teda najprv znížiť počet iterácií, tak aby tréning trval približne 5 minút a teda znížime počet iterácií z 32 000 na 3 200 a uvidíme ako veľmi nám klesne presnosť pri znížení trénovacieho času o desatinu.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/table_1shot_5minutes.png}
\caption{Výsledná tabuľka po 5tich minútach tréningu}
\label{fig:image1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/chart_compare_5min.png}
\caption{Porovnanie 5min tréningu s plným tréningom}
\label{fig:image2}
\end{figure}

Ako vidíme na obrázkoch \ref{fig:image1} a \ref{fig:image2} priemerná presnosť síce ostala celkom vysoká a presnosť pre base classes ostala dokonca vyššia, ale pre nás je najdôležitejšia presnosť pre novel classes a tá má veľmi nízke hodnoty, takže takéto skrátenie tréningu nám prinieslo veľmi zlé výsledky. Vyskúšame teda ešte skrátiť tréning na 20 minút a teda znížime počet iterácii z pôvodných 32 000 na 12 000.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/table_1shot_20minutes.png}
\caption{Výsledná tabuľka po 20tich minútach tréningu}
\label{fig:image3}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/chart_compare_20min.png}
\caption{Porovnanie 20min tréningu s plným tréningom}
\label{fig:image4}
\end{figure}

Na \ref{fig:image3} a \ref{fig:image4} vidíme výsledky po 20tich minútach. Priemerná presnosť zvýšila len trochu a vidíme taktiež, že sa nám zvýšila presnosť pre novel classes, ale stále je viac ako o polovicu nižšia ako pri plnom čase tréningu.


\section{Zrýchlenie pomocou zapamätania si výstupu zo zmrazených vrstiev}

Predošlý pokus o zrýchlenie nebol veľmi úspešný, avšak zistil som, že počas tréningu prechádza každý batch vždy celou sieťou, napriek tomu, že pri fine tuningu je takmer celá sieť zmrazená okrem poslednej vrstvy(Box Predictor). Napadlo mi teda vyskúšať prejsť zmrazenou časťou siete pre každý vstup len raz a zapamätať si výstup z tejto časti siete pre každý vstup a následne používať len tento predom vypočítaný výstup zo zmrazenej časti siete pre zvyšok tréningu. Čo by malo výrazne urýchliť prechod sieťou.

\subsection{Zapamätanie si výstupu z backbone}

Ako sme si popísali v 3.kapitole naša sieť sa skladá z 3 hlavných častí: Backbone, RPN a Roi Heads. Drvivú väčšinu našej siete tvorí Backbone, ktorej výstup ide do RPN a Roi Heads. Do Roi Heads ide taktiež výstup z RPN. V našom prípade pri fine-tuningu sú zmrazené všetky vrstvy okrem poslednej - Box Predictor. Keďže vstupom pre Box Predictor je len výstup z Box Head, potrebujeme si zapamätať výstup z Box Head. Keďže, výstupom Box Predicotra je len zoznam s dvomi hodnotami:  

\begin{enumerate}
  \item Class Prediction: pravdepodobnostné rozloženie medzi triedami objektov
  \item Bounding Box Regression: posun pôvodných súradníc bounding boxu z RPN 
\end{enumerate}

potrebujeme si taktiež zapamätať informácie o návrhoch regiónov, teda výstup z RPN, pre následné vypočítanie straty kvoli tréningu.

Keďže zapamätanie si výstupu pre každý obrázok z Box Head vrstvy, ktorá je súčasťou Roi Heads a výstup návrhov regiónov, ktoré sú výstupom z RPN, je implementačne náročnejšie. Vyskúšame najprv zapametanie si výstupu z Backbone, ktorý aj tak tvori 90\% siete a mal by priniesť výrazné zrýchlenie. Ak by nám to neprinieslo očakávané zrýchlenie, nebude mať zmysel posúvať túto myšlienku ďalej a zapamätávať si výstup priamo z Box Head a RPN pre každý obrázok, čo by malo maximalizovať rýchlosť tréningu.

Keďže, počas tréningu používame batch size veľkosti 2 a obrázky, ktoré sa berú náhodne z tréningovej množiny sú rôznej veľkosti a taktiež sú niekoľko krát resizované, tak aby bol zachovaný pomer strán. Tieto dva vybrané obrázky sú prispôsobené na rovnakú veľkosť pomocou paddingu aby mohli byť reprezentované v jednom tenzore, pred tým ako prejdu Backbonom. 

Týmto sa nám zapamätávanie výstupov veľmi komplikuje, pretože to aký padding bude pridaný na obrázok zavisí od rozmeru obrázka s ktorým je v batchi. A na to aby sme boli presný museli by sme si pamätať výstup pre každú dvojicu obrázkov zvlášť a to určite nechceme, keďže už pri 1-shot detekcii pri 21 triedach máme 21 obrázkov a každý je 11x resizovaný, čiže 231 obrázkov, teda 231x230 = 53 130 rôznych dvojíc obrázkov a rôznych príznakových máp. 

Napadá mi niekoľko možností ako to riešiť:

\subsubsection{1. Padding pre všetky obrázky na rovnakú veľkosť}

Môžme zistiť aké rozmery má najväčší batch a nastaviť padding pre každý obrázok na tieto rozmery. Všetky obrázky by tak mali rovnaký rozmer a taktiež aj ich príznaková mapa. Čiže by sme mohli vyrátať príznakovú mapu pre každý obrázok vo všetkych veľkostiach a jednoducho by sme potom takéto dve príznakové mapy spojili do batchu. Problém je v tom, že obrázky budú obsahovať zbytočne veľa paddingu, a všetky obrázky budú príliš veľke, čo taktiež veľmi spomalí náš tréning. Pri vyskúšaní tohto postupu som zistil, že tieto veľké obrázky zaberali príliš pamäte a nestačila na to ani moja grafická karta, čiže dosť zlý pokus. 

\subsubsection{2. Pispôsobiť všetky obrázky na rovnakú veľkosť}

Ďalší spôsob, ktorý mi napadol bolo nastaviť všetkým obrázkom rovnakú veľkosť a to spôsobom, že im nastavím veľkosť dlhšej hrany na veľkosť 480, kratšia hrana sa prispôsobí aby sa zachoval pomer strán a následne je obrázok doplnený paddingom tak aby mal rozmer 480x480. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/same_size_table.png}
\caption{Výsledok pre prispôsobené obrázky na rovnakú veľkosť}
\label{fig:image24}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/same_size_table.png}
\caption{Výsledok pre prispôsobené obrázky na rovnakú veľkosť}
\label{fig:image0}
\end{figure}

Tréning sa nám síce podarilo výrazne zrýchliť, trval len 13 minút a 27 sekúnd, avšak ako vidíme na obrázkoch \ref{fig:image24} a \ref{fig:image0} naša presnosť extrémne klesla. 

Takúto nízku presnosť máme hlavne preto, že náš model je testovaný na obrázkoch s veľkosťou dlhšej hrany rovnej 800. Skúsili sme teda zmeniť veľkosť testovacích obrázkov na veľkosť dlhšej hrany rovnej 480. Dosiahli sme tak podobné výsledky ako pri pôvodnom tréningu, avšak tento výsledok nie je dostatočne dôveryhodný keďže sme si prispôsobili veľkosť testovacích obrázkov ako sme potrebovali a pri reálnom používaní by bol model menej presný. 

\subsubsection{3. Použiť batch size = 1}

Doteraz sme robili tréning pri batch size veľkosti 2, vyskúšame ako bude algoritmus fungovať pri batch size \= 1. Ak bude dosahovať dobré výsledky, môže nám to uľahčiť zrýchlenie tréningu. Otestujeme to na 1-shot fine-tuningu, pretože prebieha najrýchlejšie. Prispôsobíme teda trénovacie parametre batch size zmenšíme o polovicu na 1, learning rate taktiež znížime o polovicu z 0.000125 na 0.0000625, zdvojnásobime krok z 24 000 na 48 000 a taktiež zdvojnásobime počet iterácií na 64 000.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/batch_size_comparison.png}
\caption{Porovnanie rôznych batch size}
\label{fig:image9}
\end{figure}

Na obrázku \ref{fig:image9} vidíme, že tréning pri batch size veľkosti 1 dosahuje veľmi podobné výsledky ako pri tréningu s batch size 2, avšak tréning bol menej stabilný a celková strata(total loss) počas tréningu s batch size 1 skákala z iterácie na iteráciu s oveľa väčším rozptylom. Čo môže spôsobiť rozptyl vo výsledkoch pri viacerých tréningoch. Každý tréning sa môže podariť inak a pri batch size 1 máme nižšiu konzistenciu. 

Toto sa nám ale podarilo vyriešiť pomocou zmeny Checkpointera. Checkpointer zaznamená aktuálny stav modelu a uloží ho do súboru. Predtým sme používali PeriodicCheckpointer, ktorý vytvoril checkpoint periodicky po rovnakom počte iterácií. Počet iterácii po ktorých sa spraví checkpoint je nastaviteľný a mali sme ho nastavený na 500. Použijeme však BestCheckpointer, ktorý spraví checkpoint ak bola total loss nižšia v aktuálnej iterácii ako v poslednom checkpointe. Nastavíme ho aby kontroloval každých 100 iterácií. Následne ako finálny model berieme posledný checkpoint. 

Tento tréning s batch size 1 trval dokonca o 4 minúty kratšie. Zrejmä preto, že spojiť 2 obrázky rôznych rozmerov do jedneho batchu je výpočtovo náročnejšie. A keďže osahuje veľmi dobré výsledky, stojí za to ho využiť v tomto princípe. 

\subsubsection{1.pokus}

Vyskúšame si teda zapamätať výstup z backbone pre každý obrázok a následne už backbonom prechádzať nebudeme. Uvidíme ako to zýchly náš tréning a aký výsledok dosiahneme. 

Čas nášho tréningu výrazne klesol, tréning trval iba 20minút oproti pôvodným 55min. Avšak taktiež klesla naša presnosť ako vidíme na obrázku \ref{fig:image11} v porovnaní s pôvodným tréningom. Hlavným dôvodom poklesu presnosti bude vynechávanie augmentácií počas tréningu, keďže pre každý obrázok si zapamätáme príznaky iba pre jednu transformáciu toho obrázku. Pôvodne počas sa počas tréningu aplikovali na obrázok rôzne augmentáciu a to zmena veľkosti a taktiež náhodné horizontálne otočenie. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/faster_1attempt_table.png}
\caption{Výsledok 1. pokusu}
\label{fig:image10}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/faster_1attempt_chart.png}
\caption{Graf porovnania mAP50 pôvodného algoritmu a 1. pokusu o zrýchlenie}
\label{fig:image11}
\end{figure}

\subsubsection{2.pokus}

Pre zvýšenie našej presnosti si vyskúšame zapamätať každý obrázok vo všetkých jeho šírkach. Na toto nám však nestačila pamäť v našom gpu. Preto skúsime obrázky resizovať menej krát. Pôvodne sme resizovali každý obrázok 11x na tieto veľkosti kratšej hrany obrázka: 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800. Vyskúšame to zredukovať len na 4 rôzne zmeny veľkosti aby nám stačila naša pamäť v gpu na veľkosti: 480, 608, 704, 800. Tréning trval 20 minút, takže zrýchlenie sme si zachovali a taktiež sa zvýšila naša presnosť.  Na obrázku \ref{fig:image13} vidíme presnosť v porovnaní z predošlími pokusom a taktiež pôvodným nezrýchleným tréningom. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/faster_2attempt_table.png}
\caption{Výsledok 2. pokusu}
\label{fig:image12}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/faster_2attempt_chart.png}
\caption{Graf porovnania mAP50 pôvodného algoritmu a 2. pokusu o zrýchlenie}
\label{fig:image13}
\end{figure}

Dosiahli sme solidné výsledky pri 5 násobnom zrýchlení tréningu, avšak stále sme sa nevyrovnali výsledkom pri plnom tréningu a taktiež pri vyššom počte trénovacích obrázkoch nám nebude stačiť pamäť v gpu takže pri nich to nebudeme môcť použiť. Preto sa pokúsime naše príznaky pre každý obrázok v každej veľkosti zapísať do súboru a následne čítať počas tréningu z neho. 

\subsubsection{3.pokus}

Po zapísaní príznakov každého obrázku pre všetky veľkosti do súboru bez náhodného horizontálneho otočenia. Sa náš tréning zvýšil z približne 20minút na 33 minút. Dosiahli sme ale požadované rovnaké výsledky ako pri pôvodnom 55 minútovom tréningu, dokonca o trochu lepšie. Podarilo sa nám teda zrýchliť tréning takmer o polovicu. Na obrázku \ref{fig:image14} vidíme výsledky tréningu a na obrázku \ref{fig:image15} porovnanie s pôvodným tréningom. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/faster_3attempt_table.png}
\caption{Výsledok 3. pokusu}
\label{fig:image14}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/faster_3attempt_chart.png}
\caption{Graf porovnania mAP50 pôvodného algoritmu a 3. pokusu o zrýchlenie}
\label{fig:image15}
\end{figure}


\subsection{Zapamätanie si výstupu priamo z Box Head}

Ako sme videli v predošlej časti, uloženie výstupov z Backbone vrstvy do súborov, pre každý obrázok a pre každú veľkosť zvlášť, nám urýchlilo náš tréning takmer o dvojnásobok a zachovala sa naša presnosť. Pokúsime sa teda tréning ešte zrýchliť uložením si výstupov priamo z Box Head a RPN, keďže tieto dva výstupy sú vstupom pre Box Predictor (posledná vrstva ktorú chceme trénovať).To by malo následne vo zvyšku tréningu výpočtovú zložitosť znížiť a ešte zrýchliť náš tréning. Uvidíme ako veľmi to zrýchli náš tréning v porovnaní z predošlím tréningom. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/fastest_table.png}
\caption{Výsledok zrýchleného algoritmu}
\label{fig:image16}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/fastest_chart.png}
\caption{Graf porovnania mAP50 pôvodného a zrýchleného algoritmu}
\label{fig:image17}
\end{figure}

Na obrázku \ref{fig:image16} vidíme výsledky nášho pokusu a na obrázku \ref{fig:image17} vidíme porovnanie s pôvodným pomalým algoritmom. Vidíme, že sa nám podarila dosiahnuť rovnaká presnosť. A vyrazne sa nám podarilo zrýchliť tréning celkový čas tréningu bol 6 minút a 51 sekúnd, čo je je takmer 8x rýchlejšie ako pôvodný tréning. 

Vyskušal som taktiež spustiť rôzne k-shot fine-tuningy a zaznamenal som odhadovaný čas tréningu. Porovnanie časov tréningov vidíme na obrázku \ref{fig:image16}.

\subsubsection{Vyhodnotenie}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/fastest_chart.png}
\caption{Porovnanie rýchlostí pôvodného algoritmu a algoritmu po zrýchlení}
\label{fig:image500}
\end{figure}

Na obrázku \ref{fig:image500} vidíme porovnanie rýchlosti pôvodného algoritmu a algoritmu po zrýchlení pri dosahovaní rovnakej presnosti. 






